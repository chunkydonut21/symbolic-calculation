{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## SYMBOLIC CALCULATION\n",
        "\n",
        "### Fast Accurate Symbolic Empirical Representation Of Histograms\n",
        "\n",
        "Name - Shivam Maheshwari"
      ],
      "metadata": {
        "id": "NpSymjgySZ70"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1. Dataset Preprocessing"
      ],
      "metadata": {
        "id": "xD4OlcJ-Slif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating the dataset**"
      ],
      "metadata": {
        "id": "ufSbaA8VTI1D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFaoOwaT8be2",
        "outputId": "07cec53b-e0cb-41a5-b54e-dcf039dd5c16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               function  \\\n",
            "0                               -4*x**2   \n",
            "1     -5*sin(x) + 2*sinh(x) - 2*atan(x)   \n",
            "2                  -cosh(x) + 3*asin(x)   \n",
            "3                             5*acos(x)   \n",
            "4               -log(x + 1) + 3*asin(x)   \n",
            "5        5*tan(x) - 5*acos(x) + asin(x)   \n",
            "6  -2*exp(x) - 3*log(x + 1) + 2*sinh(x)   \n",
            "7                     -x**3 + 5*atan(x)   \n",
            "8                       -4*x - 5*exp(x)   \n",
            "9                     5*exp(x) - tan(x)   \n",
            "\n",
            "                             taylor_expansion  \n",
            "0                                     -4*x**2  \n",
            "1                             11*x**3/6 - 5*x  \n",
            "2        -x**4/24 + x**3/2 - x**2/2 + 3*x - 1  \n",
            "3                    -5*x**3/6 - 5*x + 5*pi/2  \n",
            "4              x**4/4 + x**3/6 + x**2/2 + 2*x  \n",
            "5                    8*x**3/3 + 11*x - 5*pi/2  \n",
            "6          2*x**4/3 - x**3 + x**2/2 - 3*x - 2  \n",
            "7                             -8*x**3/3 + 5*x  \n",
            "8  -5*x**4/24 - 5*x**3/6 - 5*x**2/2 - 9*x - 5  \n",
            "9     5*x**4/24 + x**3/2 + 5*x**2/2 + 4*x + 5  \n",
            "Total unique expressions: 9181\n"
          ]
        }
      ],
      "source": [
        "import sympy as sp\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Define the symbolic variable\n",
        "x = sp.Symbol('x', real=True)\n",
        "\n",
        "base_functions = [\n",
        "    sp.sin(x), sp.cos(x), sp.exp(x), sp.log(1+x), sp.tan(x),\n",
        "    sp.sinh(x), sp.cosh(x), sp.asin(x), sp.acos(x), sp.atan(x),\n",
        "    x, x**2, x**3\n",
        "]\n",
        "\n",
        "def generate_random_expression(num_terms=3):\n",
        "\n",
        "    expr = 0\n",
        "    for _ in range(num_terms):\n",
        "        f = random.choice(base_functions)\n",
        "        coeff = random.randint(-5, 5)\n",
        "        expr += coeff * f\n",
        "    return expr\n",
        "\n",
        "# Number of expressions to generate\n",
        "num_expressions = 20000\n",
        "\n",
        "dataset = []\n",
        "for _ in range(num_expressions):\n",
        "    terms = random.randint(1, 3)\n",
        "    expr = generate_random_expression(num_terms=terms)\n",
        "\n",
        "    # Skip if expression is 0\n",
        "    if expr == 0:\n",
        "        continue\n",
        "\n",
        "    # Compute series expansion around x=0 up to x^4\n",
        "    # Sympy's 'order=5' generates terms up to x^4, then we remove O(x^5)\n",
        "    series_expr = sp.series(expr, x, 0, 5).removeO()\n",
        "\n",
        "    dataset.append((str(expr), str(series_expr)))\n",
        "\n",
        "\n",
        "df = pd.DataFrame(dataset, columns=[\"function\", \"taylor_expansion\"])\n",
        "\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_csv(\"taylor_dataset_extended.csv\", index=False)\n",
        "\n",
        "print(df.head(10))\n",
        "print(f\"Total unique expressions: {len(df)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_backup = df.copy()"
      ],
      "metadata": {
        "id": "KBXQ_05MB6lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenising the dataset**"
      ],
      "metadata": {
        "id": "q7PjtohkTFeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_expression(expr):\n",
        "    return list(expr)\n",
        "\n",
        "def add_special_tokens(expr):\n",
        "    # Insert single-character tokens for start/end\n",
        "    return f\"¶{expr}µ\"\n",
        "\n",
        "df[\"taylor_expansion\"] = df[\"taylor_expansion\"].apply(add_special_tokens)\n",
        "\n",
        "# Create new columns in the DataFrame with token lists\n",
        "df[\"function_tokens\"] = df[\"function\"].apply(tokenize_expression)\n",
        "df[\"taylor_tokens\"] = df[\"taylor_expansion\"].apply(tokenize_expression)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AKxW2UP_FtX",
        "outputId": "c7f73888-8c3f-4526-8541-523394a4586f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            function                        taylor_expansion  \\\n",
            "0                            -4*x**2                               ¶-4*x**2µ   \n",
            "1  -5*sin(x) + 2*sinh(x) - 2*atan(x)                       ¶11*x**3/6 - 5*xµ   \n",
            "2               -cosh(x) + 3*asin(x)  ¶-x**4/24 + x**3/2 - x**2/2 + 3*x - 1µ   \n",
            "3                          5*acos(x)              ¶-5*x**3/6 - 5*x + 5*pi/2µ   \n",
            "4            -log(x + 1) + 3*asin(x)        ¶x**4/4 + x**3/6 + x**2/2 + 2*xµ   \n",
            "\n",
            "                                     function_tokens  \\\n",
            "0                              [-, 4, *, x, *, *, 2]   \n",
            "1  [-, 5, *, s, i, n, (, x, ),  , +,  , 2, *, s, ...   \n",
            "2  [-, c, o, s, h, (, x, ),  , +,  , 3, *, a, s, ...   \n",
            "3                        [5, *, a, c, o, s, (, x, )]   \n",
            "4  [-, l, o, g, (, x,  , +,  , 1, ),  , +,  , 3, ...   \n",
            "\n",
            "                                       taylor_tokens  \n",
            "0                        [¶, -, 4, *, x, *, *, 2, µ]  \n",
            "1  [¶, 1, 1, *, x, *, *, 3, /, 6,  , -,  , 5, *, ...  \n",
            "2  [¶, -, x, *, *, 4, /, 2, 4,  , +,  , x, *, *, ...  \n",
            "3  [¶, -, 5, *, x, *, *, 3, /, 6,  , -,  , 5, *, ...  \n",
            "4  [¶, x, *, *, 4, /, 4,  , +,  , x, *, *, 3, /, ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2: LSTM Model"
      ],
      "metadata": {
        "id": "ItHNMcZDT0cW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the LSTM model**"
      ],
      "metadata": {
        "id": "Tz13niD8T3nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# 1) Tokenize and Pad\n",
        "function_texts = df[\"function\"].tolist()\n",
        "taylor_texts = df[\"taylor_expansion\"].tolist()\n",
        "\n",
        "# Character-level tokenizer\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(function_texts + taylor_texts)\n",
        "\n",
        "\n",
        "input_sequences = tokenizer.texts_to_sequences(function_texts)\n",
        "output_sequences = tokenizer.texts_to_sequences(taylor_texts)\n",
        "\n",
        "# debug\n",
        "for i in range(3):\n",
        "    print(\"Original expansion:\", taylor_texts[i])\n",
        "    print(\"Token IDs:\", output_sequences[i][:15])\n",
        "\n",
        "\n",
        "max_input_length = 50\n",
        "max_output_length = 50\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_input_length, padding='post')\n",
        "output_sequences = pad_sequences(output_sequences, maxlen=max_output_length, padding='post')\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 50\n",
        "latent_dim = 128\n",
        "\n",
        "# right and left shift the decoder\n",
        "decoder_input_data = np.zeros_like(output_sequences)\n",
        "decoder_input_data[:, 1:] = output_sequences[:, :-1]\n",
        "\n",
        "decoder_target_data = np.zeros_like(output_sequences)\n",
        "decoder_target_data[:, :-1] = output_sequences[:, 1:]\n",
        "decoder_target_data = np.expand_dims(decoder_target_data, -1)\n",
        "\n",
        "# 4) Define the Encoder\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb = Embedding(vocab_size, embedding_dim)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "_, encoder_hidden_state, encoder_cell_state = encoder_lstm(enc_emb)\n",
        "encoder_states = [encoder_hidden_state, encoder_cell_state]\n",
        "\n",
        "# 5) Define the Decoder\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb = Embedding(vocab_size, embedding_dim)(decoder_inputs)\n",
        "decoder_lstm_layer = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm_layer(dec_emb, initial_state=encoder_states)\n",
        "decoder_dense = Dense(vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# 6) Build and Compile the Seq2seq Model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.summary()\n",
        "\n",
        "# 7) Train the Model\n",
        "history_lstm = model.fit(\n",
        "    [input_sequences, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=64,\n",
        "    epochs=100,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lxbCMoKk_Hb-",
        "outputId": "a3c84800-6914-4a7c-8a9a-a77831724595"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original expansion: ¶-4*x**2µ\n",
            "Token IDs: [14, 4, 11, 1, 3, 1, 1, 5, 15]\n",
            "Original expansion: ¶11*x**3/6 - 5*xµ\n",
            "Token IDs: [14, 20, 20, 1, 3, 1, 1, 6, 10, 22, 2, 4, 2, 13, 1]\n",
            "Original expansion: ¶-x**4/24 + x**3/2 - x**2/2 + 3*x - 1µ\n",
            "Token IDs: [14, 4, 3, 1, 1, 11, 10, 5, 11, 2, 7, 2, 3, 1, 1]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)       │          \u001b[38;5;34m1,650\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)       │          \u001b[38;5;34m1,650\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │         \u001b[38;5;34m91,648\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│                           │ \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)]     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),    │         \u001b[38;5;34m91,648\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m] │\n",
              "│                           │ \u001b[38;5;34m128\u001b[0m)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m)       │          \u001b[38;5;34m4,257\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,650</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,650</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">91,648</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]     │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">91,648</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>] │\n",
              "│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)]                  │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,257</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m190,853\u001b[0m (745.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">190,853</span> (745.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m190,853\u001b[0m (745.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">190,853</span> (745.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 1.9160 - val_loss: 0.7859\n",
            "Epoch 2/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.6573 - val_loss: 0.4978\n",
            "Epoch 3/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4602 - val_loss: 0.4390\n",
            "Epoch 4/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.4191 - val_loss: 0.4104\n",
            "Epoch 5/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3898 - val_loss: 0.3882\n",
            "Epoch 6/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3729 - val_loss: 0.3693\n",
            "Epoch 7/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3521 - val_loss: 0.3590\n",
            "Epoch 8/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.3365 - val_loss: 0.3431\n",
            "Epoch 9/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.3215 - val_loss: 0.3324\n",
            "Epoch 10/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.3134 - val_loss: 0.3196\n",
            "Epoch 11/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.3027 - val_loss: 0.3139\n",
            "Epoch 12/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2968 - val_loss: 0.3062\n",
            "Epoch 13/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2891 - val_loss: 0.2990\n",
            "Epoch 14/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2812 - val_loss: 0.2927\n",
            "Epoch 15/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2762 - val_loss: 0.2865\n",
            "Epoch 16/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2718 - val_loss: 0.2799\n",
            "Epoch 17/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2648 - val_loss: 0.2754\n",
            "Epoch 18/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.2567 - val_loss: 0.2672\n",
            "Epoch 19/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2512 - val_loss: 0.2605\n",
            "Epoch 20/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2415 - val_loss: 0.2571\n",
            "Epoch 21/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2372 - val_loss: 0.2526\n",
            "Epoch 22/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2325 - val_loss: 0.2491\n",
            "Epoch 23/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2259 - val_loss: 0.2443\n",
            "Epoch 24/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2210 - val_loss: 0.2346\n",
            "Epoch 25/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2128 - val_loss: 0.2286\n",
            "Epoch 26/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.2084 - val_loss: 0.2278\n",
            "Epoch 27/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.2048 - val_loss: 0.2235\n",
            "Epoch 28/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2028 - val_loss: 0.2211\n",
            "Epoch 29/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1962 - val_loss: 0.2113\n",
            "Epoch 30/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1906 - val_loss: 0.2067\n",
            "Epoch 31/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1856 - val_loss: 0.2054\n",
            "Epoch 32/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1813 - val_loss: 0.2034\n",
            "Epoch 33/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1782 - val_loss: 0.2003\n",
            "Epoch 34/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1748 - val_loss: 0.1948\n",
            "Epoch 35/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.1688 - val_loss: 0.1945\n",
            "Epoch 36/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.1690 - val_loss: 0.1924\n",
            "Epoch 37/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1648 - val_loss: 0.1912\n",
            "Epoch 38/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1632 - val_loss: 0.1880\n",
            "Epoch 39/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1590 - val_loss: 0.1846\n",
            "Epoch 40/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1568 - val_loss: 0.1859\n",
            "Epoch 41/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1562 - val_loss: 0.1838\n",
            "Epoch 42/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1529 - val_loss: 0.1826\n",
            "Epoch 43/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1510 - val_loss: 0.1806\n",
            "Epoch 44/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1474 - val_loss: 0.1772\n",
            "Epoch 45/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.1431 - val_loss: 0.1750\n",
            "Epoch 46/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1412 - val_loss: 0.1747\n",
            "Epoch 47/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1382 - val_loss: 0.1721\n",
            "Epoch 48/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1359 - val_loss: 0.1714\n",
            "Epoch 49/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1314 - val_loss: 0.1694\n",
            "Epoch 50/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1301 - val_loss: 0.1702\n",
            "Epoch 51/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1266 - val_loss: 0.1659\n",
            "Epoch 52/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1229 - val_loss: 0.1671\n",
            "Epoch 53/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.1205 - val_loss: 0.1617\n",
            "Epoch 54/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1166 - val_loss: 0.1609\n",
            "Epoch 55/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1146 - val_loss: 0.1611\n",
            "Epoch 56/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.1133 - val_loss: 0.1579\n",
            "Epoch 57/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1092 - val_loss: 0.1551\n",
            "Epoch 58/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1066 - val_loss: 0.1550\n",
            "Epoch 59/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1026 - val_loss: 0.1556\n",
            "Epoch 60/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.1021 - val_loss: 0.1516\n",
            "Epoch 61/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0993 - val_loss: 0.1499\n",
            "Epoch 62/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0959 - val_loss: 0.1537\n",
            "Epoch 63/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0937 - val_loss: 0.1535\n",
            "Epoch 64/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0929 - val_loss: 0.1508\n",
            "Epoch 65/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0903 - val_loss: 0.1490\n",
            "Epoch 66/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0859 - val_loss: 0.1507\n",
            "Epoch 67/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0840 - val_loss: 0.1509\n",
            "Epoch 68/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0828 - val_loss: 0.1479\n",
            "Epoch 69/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0826 - val_loss: 0.1462\n",
            "Epoch 70/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0780 - val_loss: 0.1489\n",
            "Epoch 71/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0773 - val_loss: 0.1448\n",
            "Epoch 72/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0755 - val_loss: 0.1455\n",
            "Epoch 73/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0718 - val_loss: 0.1489\n",
            "Epoch 74/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0712 - val_loss: 0.1454\n",
            "Epoch 75/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0669 - val_loss: 0.1487\n",
            "Epoch 76/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0697 - val_loss: 0.1490\n",
            "Epoch 77/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0678 - val_loss: 0.1453\n",
            "Epoch 78/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0648 - val_loss: 0.1480\n",
            "Epoch 79/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0649 - val_loss: 0.1478\n",
            "Epoch 80/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0622 - val_loss: 0.1480\n",
            "Epoch 81/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0615 - val_loss: 0.1462\n",
            "Epoch 82/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0608 - val_loss: 0.1456\n",
            "Epoch 83/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0589 - val_loss: 0.1471\n",
            "Epoch 84/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0566 - val_loss: 0.1486\n",
            "Epoch 85/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0553 - val_loss: 0.1513\n",
            "Epoch 86/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0558 - val_loss: 0.1461\n",
            "Epoch 87/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0522 - val_loss: 0.1492\n",
            "Epoch 88/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0514 - val_loss: 0.1553\n",
            "Epoch 89/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0514 - val_loss: 0.1540\n",
            "Epoch 90/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0503 - val_loss: 0.1489\n",
            "Epoch 91/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0485 - val_loss: 0.1528\n",
            "Epoch 92/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0476 - val_loss: 0.1566\n",
            "Epoch 93/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0482 - val_loss: 0.1530\n",
            "Epoch 94/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0466 - val_loss: 0.1551\n",
            "Epoch 95/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0465 - val_loss: 0.1557\n",
            "Epoch 96/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0460 - val_loss: 0.1562\n",
            "Epoch 97/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0438 - val_loss: 0.1525\n",
            "Epoch 98/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0421 - val_loss: 0.1541\n",
            "Epoch 99/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0421 - val_loss: 0.1550\n",
            "Epoch 100/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0388 - val_loss: 0.1584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3: Transformer Model"
      ],
      "metadata": {
        "id": "uFWRwmB-VVYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LayerNormalization, Dropout, Input, Lambda\n",
        "\n",
        "# Positional Encoding Function\n",
        "def get_positional_encoding(max_len, d_model):\n",
        "    pos_enc = np.zeros((max_len, d_model))\n",
        "    for pos in range(max_len):\n",
        "        for i in range(0, d_model, 2):\n",
        "            pos_enc[pos, i] = np.sin(pos / (10000 ** ((2 * i) / d_model)))\n",
        "            if i + 1 < d_model:\n",
        "                pos_enc[pos, i + 1] = np.cos(pos / (10000 ** ((2 * (i+1)) / d_model)))\n",
        "    return tf.cast(pos_enc, dtype=tf.float32)\n",
        "\n",
        "# Transformer Encoder Block\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    attn_output = tf.keras.layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads\n",
        "    )(inputs, inputs)\n",
        "    attn_output = Dropout(dropout)(attn_output)\n",
        "    out1 = LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
        "\n",
        "    ffn_output = Dense(ff_dim, activation=\"relu\")(out1)\n",
        "    ffn_output = Dense(inputs.shape[-1])(ffn_output)\n",
        "    ffn_output = Dropout(dropout)(ffn_output)\n",
        "    return LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n",
        "\n",
        "# Transformer Decoder Block with causal masking\n",
        "def transformer_decoder(inputs, enc_output, head_size, num_heads, ff_dim, dropout=0):\n",
        "    causal_mask = Lambda(\n",
        "        lambda x: tf.tile(\n",
        "            tf.expand_dims(tf.linalg.band_part(tf.ones((tf.shape(x)[1], tf.shape(x)[1])), -1, 0), 0),\n",
        "            [tf.shape(x)[0], 1, 1]\n",
        "        )\n",
        "    )(inputs)\n",
        "\n",
        "    attn1 = tf.keras.layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads\n",
        "    )(inputs, inputs, attention_mask=causal_mask)\n",
        "    attn1 = Dropout(dropout)(attn1)\n",
        "    out1 = LayerNormalization(epsilon=1e-6)(inputs + attn1)\n",
        "\n",
        "    attn2 = tf.keras.layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads\n",
        "    )(out1, enc_output)\n",
        "    attn2 = Dropout(dropout)(attn2)\n",
        "    out2 = LayerNormalization(epsilon=1e-6)(out1 + attn2)\n",
        "\n",
        "    ffn_output = Dense(ff_dim, activation=\"relu\")(out2)\n",
        "    ffn_output = Dense(out2.shape[-1])(ffn_output)\n",
        "    ffn_output = Dropout(dropout)(ffn_output)\n",
        "    return LayerNormalization(epsilon=1e-6)(out2 + ffn_output)\n",
        "\n",
        "# hyperparameters\n",
        "embedding_dim = 64\n",
        "head_size = 64\n",
        "num_heads = 4\n",
        "ff_dim = 128\n",
        "num_encoder_layers = 2\n",
        "num_decoder_layers = 2\n",
        "dropout_rate = 0.1\n",
        "\n",
        "# Build the Model\n",
        "encoder_inputs = Input(shape=(max_input_length,))\n",
        "decoder_inputs = Input(shape=(max_output_length,))\n",
        "\n",
        "# Encoder embedding with positional encoding\n",
        "enc_emb = Embedding(vocab_size, embedding_dim, mask_zero=True)(encoder_inputs)\n",
        "pos_encoding_enc = get_positional_encoding(max_input_length, embedding_dim)\n",
        "enc_emb = enc_emb + pos_encoding_enc\n",
        "\n",
        "enc_output = enc_emb\n",
        "for _ in range(num_encoder_layers):\n",
        "    enc_output = transformer_encoder(enc_output, head_size, num_heads, ff_dim, dropout_rate)\n",
        "\n",
        "# Decoder embedding with positional encoding\n",
        "dec_emb = Embedding(vocab_size, embedding_dim, mask_zero=True)(decoder_inputs)\n",
        "pos_encoding_dec = get_positional_encoding(max_output_length, embedding_dim)\n",
        "dec_emb = dec_emb + pos_encoding_dec\n",
        "\n",
        "dec_output = dec_emb\n",
        "for _ in range(num_decoder_layers):\n",
        "    dec_output = transformer_decoder(dec_output, enc_output, head_size, num_heads, ff_dim, dropout_rate)\n",
        "\n",
        "# Final output dense layer\n",
        "outputs = Dense(vocab_size, activation=\"softmax\")(dec_output)\n",
        "\n",
        "transformer_model = Model([encoder_inputs, decoder_inputs], outputs)\n",
        "transformer_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=\"sparse_categorical_crossentropy\"\n",
        ")\n",
        "\n",
        "transformer_model.summary()\n",
        "\n",
        "# 4) Train the Model\n",
        "history_transformer = transformer_model.fit(\n",
        "    [input_sequences, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=64,\n",
        "    epochs=100,\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3WtGXluB_MCD",
        "outputId": "b9be3d8e-550a-4caa-92b9-6d80f1c00c66"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m2,112\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m66,368\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
              "│                           │                        │                │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │          \u001b[38;5;34m8,320\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m8,256\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                           │                        │                │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m66,368\u001b[0m │ layer_normalization_1… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m2,112\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │          \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m66,368\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│                           │                        │                │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m8,256\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│                           │                        │                │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_2… │\n",
              "│                           │                        │                │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_3    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m66,368\u001b[0m │ layer_normalization_4… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_4… │\n",
              "│                           │                        │                │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │          \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m8,256\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_5… │\n",
              "│                           │                        │                │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_6     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_4    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m66,368\u001b[0m │ layer_normalization_6… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_6… │\n",
              "│                           │                        │                │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_9 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_6… │\n",
              "│                           │                        │                │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_5    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m66,368\u001b[0m │ layer_normalization_7… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_10 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_7… │\n",
              "│                           │                        │                │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_8     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │          \u001b[38;5;34m8,320\u001b[0m │ layer_normalization_8… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │          \u001b[38;5;34m8,256\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_11 (\u001b[38;5;33mAdd\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ layer_normalization_8… │\n",
              "│                           │                        │                │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_9     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │            \u001b[38;5;34m128\u001b[0m │ add_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m33\u001b[0m)         │          \u001b[38;5;34m2,145\u001b[0m │ layer_normalization_9… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
              "│                           │                        │                │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                           │                        │                │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalization_1… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1… │\n",
              "│                           │                        │                │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│                           │                        │                │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│                           │                        │                │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2… │\n",
              "│                           │                        │                │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_3    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalization_4… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4… │\n",
              "│                           │                        │                │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_5… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5… │\n",
              "│                           │                        │                │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_6     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_4    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalization_6… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_6… │\n",
              "│                           │                        │                │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6… │\n",
              "│                           │                        │                │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_5    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalization_7… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_7… │\n",
              "│                           │                        │                │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_8     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization_8… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_8… │\n",
              "│                           │                        │                │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_9     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,145</span> │ layer_normalization_9… │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m472,161\u001b[0m (1.80 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">472,161</span> (1.80 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m472,161\u001b[0m (1.80 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">472,161</span> (1.80 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 172ms/step - loss: 1.4741 - val_loss: 0.5845\n",
            "Epoch 2/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.5242 - val_loss: 0.4268\n",
            "Epoch 3/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 0.4163 - val_loss: 0.3818\n",
            "Epoch 4/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.3741 - val_loss: 0.3472\n",
            "Epoch 5/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.3343 - val_loss: 0.3087\n",
            "Epoch 6/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.2983 - val_loss: 0.2731\n",
            "Epoch 7/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.2657 - val_loss: 0.2505\n",
            "Epoch 8/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.2456 - val_loss: 0.2313\n",
            "Epoch 9/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.2249 - val_loss: 0.2170\n",
            "Epoch 10/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.2089 - val_loss: 0.2076\n",
            "Epoch 11/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - loss: 0.1969 - val_loss: 0.1981\n",
            "Epoch 12/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.1912 - val_loss: 0.1889\n",
            "Epoch 13/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.1804 - val_loss: 0.1811\n",
            "Epoch 14/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.1763 - val_loss: 0.1774\n",
            "Epoch 15/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.1690 - val_loss: 0.1727\n",
            "Epoch 16/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.1640 - val_loss: 0.1649\n",
            "Epoch 17/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.1563 - val_loss: 0.1628\n",
            "Epoch 18/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.1515 - val_loss: 0.1604\n",
            "Epoch 19/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.1476 - val_loss: 0.1551\n",
            "Epoch 20/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.1438 - val_loss: 0.1503\n",
            "Epoch 21/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.1410 - val_loss: 0.1461\n",
            "Epoch 22/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.1374 - val_loss: 0.1439\n",
            "Epoch 23/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.1339 - val_loss: 0.1453\n",
            "Epoch 24/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.1282 - val_loss: 0.1331\n",
            "Epoch 25/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.1247 - val_loss: 0.1339\n",
            "Epoch 26/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.1223 - val_loss: 0.1271\n",
            "Epoch 27/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.1160 - val_loss: 0.1238\n",
            "Epoch 28/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.1132 - val_loss: 0.1199\n",
            "Epoch 29/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.1087 - val_loss: 0.1206\n",
            "Epoch 30/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.1070 - val_loss: 0.1136\n",
            "Epoch 31/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.1013 - val_loss: 0.1109\n",
            "Epoch 32/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.1000 - val_loss: 0.1103\n",
            "Epoch 33/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0953 - val_loss: 0.1059\n",
            "Epoch 34/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0909 - val_loss: 0.1024\n",
            "Epoch 35/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0911 - val_loss: 0.1018\n",
            "Epoch 36/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0871 - val_loss: 0.1004\n",
            "Epoch 37/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0868 - val_loss: 0.0950\n",
            "Epoch 38/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0836 - val_loss: 0.0960\n",
            "Epoch 39/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0827 - val_loss: 0.0928\n",
            "Epoch 40/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0799 - val_loss: 0.0928\n",
            "Epoch 41/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0907 - val_loss: 0.0910\n",
            "Epoch 42/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0753 - val_loss: 0.0891\n",
            "Epoch 43/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0734 - val_loss: 0.0901\n",
            "Epoch 44/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0726 - val_loss: 0.0866\n",
            "Epoch 45/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0749 - val_loss: 0.0850\n",
            "Epoch 46/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0709 - val_loss: 0.0851\n",
            "Epoch 47/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0698 - val_loss: 0.0824\n",
            "Epoch 48/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0677 - val_loss: 0.0834\n",
            "Epoch 49/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0663 - val_loss: 0.0823\n",
            "Epoch 50/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0641 - val_loss: 0.0815\n",
            "Epoch 51/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0636 - val_loss: 0.0809\n",
            "Epoch 52/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0616 - val_loss: 0.0795\n",
            "Epoch 53/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0636 - val_loss: 0.0799\n",
            "Epoch 54/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0603 - val_loss: 0.0787\n",
            "Epoch 55/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0598 - val_loss: 0.0763\n",
            "Epoch 56/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0590 - val_loss: 0.0787\n",
            "Epoch 57/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0573 - val_loss: 0.0749\n",
            "Epoch 58/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0588 - val_loss: 0.0764\n",
            "Epoch 59/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0550 - val_loss: 0.0749\n",
            "Epoch 60/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0555 - val_loss: 0.0733\n",
            "Epoch 61/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0534 - val_loss: 0.0733\n",
            "Epoch 62/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0544 - val_loss: 0.0731\n",
            "Epoch 63/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 0.0528 - val_loss: 0.0755\n",
            "Epoch 64/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0550 - val_loss: 0.0695\n",
            "Epoch 65/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0512 - val_loss: 0.0677\n",
            "Epoch 66/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0504 - val_loss: 0.0740\n",
            "Epoch 67/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0516 - val_loss: 0.0673\n",
            "Epoch 68/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0495 - val_loss: 0.0718\n",
            "Epoch 69/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0489 - val_loss: 0.0672\n",
            "Epoch 70/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0484 - val_loss: 0.0654\n",
            "Epoch 71/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0483 - val_loss: 0.0668\n",
            "Epoch 72/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0460 - val_loss: 0.0634\n",
            "Epoch 73/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0463 - val_loss: 0.0732\n",
            "Epoch 74/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0478 - val_loss: 0.0651\n",
            "Epoch 75/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0446 - val_loss: 0.0647\n",
            "Epoch 76/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0438 - val_loss: 0.0656\n",
            "Epoch 77/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0444 - val_loss: 0.0641\n",
            "Epoch 78/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0444 - val_loss: 0.0636\n",
            "Epoch 79/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0447 - val_loss: 0.0649\n",
            "Epoch 80/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0427 - val_loss: 0.0620\n",
            "Epoch 81/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0412 - val_loss: 0.0638\n",
            "Epoch 82/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0416 - val_loss: 0.0603\n",
            "Epoch 83/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0410 - val_loss: 0.0634\n",
            "Epoch 84/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0408 - val_loss: 0.0609\n",
            "Epoch 85/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0405 - val_loss: 0.0606\n",
            "Epoch 86/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0407 - val_loss: 0.0635\n",
            "Epoch 87/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0396 - val_loss: 0.0630\n",
            "Epoch 88/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0387 - val_loss: 0.0575\n",
            "Epoch 89/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0367 - val_loss: 0.0610\n",
            "Epoch 90/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0410 - val_loss: 0.0659\n",
            "Epoch 91/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0429 - val_loss: 0.0584\n",
            "Epoch 92/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0369 - val_loss: 0.0571\n",
            "Epoch 93/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0355 - val_loss: 0.0586\n",
            "Epoch 94/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0353 - val_loss: 0.0561\n",
            "Epoch 95/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0344 - val_loss: 0.0565\n",
            "Epoch 96/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0336 - val_loss: 0.0592\n",
            "Epoch 97/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0346 - val_loss: 0.0577\n",
            "Epoch 98/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0344 - val_loss: 0.0566\n",
            "Epoch 99/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0336 - val_loss: 0.0535\n",
            "Epoch 100/100\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0309 - val_loss: 0.0596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history_transformer.history['loss'], label='Training Loss')\n",
        "plt.plot(history_transformer.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Transformer Training vs. Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# predictions\n",
        "predictions = transformer_model.predict([input_sequences, output_sequences])\n",
        "predicted_sequences = np.argmax(predictions, axis=-1)\n",
        "\n",
        "\n",
        "# decode sequence back to strings\n",
        "def decode_sequence(seq, tokenizer):\n",
        "    reverse_word_index = {v: k for k, v in tokenizer.word_index.items()}\n",
        "    tokens = [reverse_word_index.get(num, '') for num in seq if num != 0]\n",
        "    out_str = ''.join(tokens)\n",
        "    # remove special tokens like '¶' or 'µ', remove them\n",
        "    out_str = out_str.replace('¶', '').replace('µ', '')\n",
        "    return out_str\n",
        "\n",
        "# display some examples\n",
        "num_examples = 5\n",
        "for i in range(num_examples):\n",
        "    input_str = decode_sequence(input_sequences[i], tokenizer)\n",
        "    true_str = decode_sequence(output_sequences[i], tokenizer)\n",
        "    pred_str = decode_sequence(predicted_sequences[i], tokenizer)\n",
        "    print(f\"Example {i+1}\")\n",
        "    print(\"Input Function:     \", input_str)\n",
        "    print(\"True Taylor:        \", true_str)\n",
        "    print(\"Predicted Taylor:   \", pred_str)\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "\n",
        "bleu_scores = []\n",
        "# Smoothing helps avoid zero BLEU for short sequences\n",
        "smooth_fn = SmoothingFunction().method1\n",
        "\n",
        "for i in range(len(output_sequences)):\n",
        "    # Prepare reference and candidate as lists of characters (for char-level)\n",
        "    reference = [list(decode_sequence(output_sequences[i], tokenizer))]\n",
        "    candidate = list(decode_sequence(predicted_sequences[i], tokenizer))\n",
        "    score = sentence_bleu(reference, candidate, smoothing_function=smooth_fn)\n",
        "    bleu_scores.append(score)\n",
        "\n",
        "average_bleu = np.mean(bleu_scores)\n",
        "print(\"Average BLEU Score on Test Set:\", average_bleu)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tH8Vr-2e_VQ8",
        "outputId": "7e5acd13-8a93-44e9-a447-621a05e5db95"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m287/287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "Example 1\n",
            "Input Function:      -4*x**2\n",
            "True Taylor:         -4*x**2\n",
            "Predicted Taylor:    4*x**2\n",
            "------------------------------\n",
            "Example 2\n",
            "Input Function:      -5*sin(x) + 2*sinh(x) - 2*atan(x)\n",
            "True Taylor:         11*x**3/6 - 5*x\n",
            "Predicted Taylor:    *xx**3/6 - 3*x\n",
            "------------------------------\n",
            "Example 3\n",
            "Input Function:      -cosh(x) + 3*asin(x)\n",
            "True Taylor:         -x**4/24 + x**3/2 - x**2/2 + 3*x - 1\n",
            "Predicted Taylor:    ***4/24 + x**3/2 - x**2/2 + 3*x - 1\n",
            "------------------------------\n",
            "Example 4\n",
            "Input Function:      5*acos(x)\n",
            "True Taylor:         -5*x**3/6 - 5*x + 5*pi/2\n",
            "Predicted Taylor:    **x**3/6 - 5*x + 5*pi/2\n",
            "------------------------------\n",
            "Example 5\n",
            "Input Function:      -log(x + 1) + 3*asin(x)\n",
            "True Taylor:         x**4/4 + x**3/6 + x**2/2 + 2*x\n",
            "Predicted Taylor:    **4/4 + x**3/6 + x**2/2 + 2*x\n",
            "------------------------------\n",
            "Average BLEU Score on Test Set: 0.8930689371586087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s4TtAgxgEa8F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}